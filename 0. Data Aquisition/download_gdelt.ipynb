{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from requests import RequestException # all possible errors when downloading centered in one exception\n",
    "# from requests import ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError # possible errors when downloading\n",
    "from bs4 import BeautifulSoup\n",
    "from download import download\n",
    "import os\n",
    "import numpy as np\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/luisquinonespr/code/BSE/thesis'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: put here the directory of the GDELTnowcast on Dropbox:\n",
    "dfolder = \"data/\"\n",
    "os.makedirs(dfolder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: # GDELT (header) names; I manually input it in every\n",
    "# iteration. Important, there are two types of headers: before and after March2013.\n",
    "cnames_bef = ['GLOBALEVENTID', 'SQLDATE', 'MonthYear', \n",
    "              'Year', 'FractionDate', 'Actor1Code', 'Actor1Name', \n",
    "              'Actor1CountryCode', 'Actor1KnownGroupCode', 'Actor1EthnicCode', 'Actor1Religion1Code',\n",
    "              'Actor1Religion2Code', 'Actor1Type1Code', 'Actor1Type2Code', 'Actor1Type3Code', 'Actor2Code',\n",
    "              'Actor2Name', 'Actor2CountryCode', 'Actor2KnownGroupCode', 'Actor2EthnicCode', 'Actor2Religion1Code', \n",
    "                  'Actor2Religion2Code', 'Actor2Type1Code', 'Actor2Type2Code', 'Actor2Type3Code', 'IsRootEvent', 'EventCode', \n",
    "                  'EventBaseCode', 'EventRootCode', 'QuadClass', 'GoldsteinScale', 'NumMentions', 'NumSources', 'NumArticles',\n",
    "                    'AvgTone', 'Actor1Geo_Type', 'Actor1Geo_FullName', 'Actor1Geo_CountryCode', 'Actor1Geo_ADM1Code', 'Actor1Geo_Lat', 'Actor1Geo_Long',\n",
    "                      'Actor1Geo_FeatureID', 'Actor2Geo_Type', 'Actor2Geo_FullName', 'Actor2Geo_CountryCode', 'Actor2Geo_ADM1Code', 'Actor2Geo_Lat', 'Actor2Geo_Long', \n",
    "                        'Actor2Geo_FeatureID', 'ActionGeo_Type', 'ActionGeo_FullName', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code', 'ActionGeo_Lat', 'ActionGeo_Long', \n",
    "                        'ActionGeo_FeatureID', 'DATEADDED']\n",
    "\n",
    "cnames_aft = ['GLOBALEVENTID', 'SQLDATE', 'MonthYear', \n",
    "              'Year', 'FractionDate', 'Actor1Code', \n",
    "              'Actor1Name', 'Actor1CountryCode', 'Actor1KnownGroupCode', 'Actor1EthnicCode', 'Actor1Religion1Code', \n",
    "              'Actor1Religion2Code', 'Actor1Type1Code', 'Actor1Type2Code', 'Actor1Type3Code', 'Actor2Code', 'Actor2Name',\n",
    "                'Actor2CountryCode', 'Actor2KnownGroupCode', 'Actor2EthnicCode', 'Actor2Religion1Code', 'Actor2Religion2Code',\n",
    "                  'Actor2Type1Code', 'Actor2Type2Code', 'Actor2Type3Code', 'IsRootEvent', 'EventCode', 'EventBaseCode', 'EventRootCode',\n",
    "                    'QuadClass', 'GoldsteinScale', 'NumMentions', 'NumSources', 'NumArticles', 'AvgTone', 'Actor1Geo_Type', 'Actor1Geo_FullName',\n",
    "                      'Actor1Geo_CountryCode', 'Actor1Geo_ADM1Code', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor1Geo_FeatureID', 'Actor2Geo_Type', 'Actor2Geo_FullName',\n",
    "                        'Actor2Geo_CountryCode', 'Actor2Geo_ADM1Code', 'Actor2Geo_Lat', 'Actor2Geo_Long', 'Actor2Geo_FeatureID', 'ActionGeo_Type', 'ActionGeo_FullName', \n",
    "                        'ActionGeo_CountryCode', 'ActionGeo_ADM1Code', 'ActionGeo_Lat', 'ActionGeo_Long', 'ActionGeo_FeatureID', 'DATEADDED', 'SOURCEURL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: list of variables to be created in the final dataset:\n",
    "var_list = ['count_events_1', 'count_events_2', 'count_events_3', 'count_events_4', 'count_events_5', 'count_events_6', 'count_events_7', 'count_events_8',\n",
    "'count_events_9', 'count_events_10', 'count_events_11', 'count_events_12', 'count_events_13', 'count_events_14', 'count_events_15', 'count_events_16', 'count_events_17', 'count_events_18', 'count_events_19', 'count_events_20',\n",
    "'count_events_1_gov', 'count_events_2_gov', 'count_events_3_gov', 'count_events_4_gov', 'count_events_5_gov', 'count_events_6_gov', 'count_events_7_gov',\n",
    "'count_events_8_gov', 'count_events_9_gov', 'count_events_10_gov', 'count_events_11_gov', 'count_events_12_gov', 'count_events_13_gov', 'count_events_14_gov',\n",
    "'count_events_15_gov', 'count_events_16_gov', 'count_events_17_gov', 'count_events_18_gov', 'count_events_19_gov', 'count_events_20_gov', 'count_events_1_opp', 'count_events_2_opp', 'count_events_3_opp', 'count_events_4_opp', 'count_events_5_opp', 'count_events_6_opp', 'count_events_7_opp',\n",
    "'count_events_8_opp', 'count_events_9_opp', 'count_events_10_opp', 'count_events_11_opp', 'count_events_12_opp', 'count_events_13_opp', 'count_events_14_opp',\n",
    "'count_events_15_opp', 'count_events_16_opp', 'count_events_17_opp', 'count_events_18_opp', 'count_events_19_opp', 'count_events_20_opp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: creating list of links of all GDELT events' files:\n",
    "links = requests.get('http://data.gdeltproject.org/events/index.html')\n",
    "links = BeautifulSoup(links.content, \"html5lib\") # processing its content\n",
    "links = links.find_all('a') # getting the links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: creating (or loading) the list of files that have been already\n",
    "# downloaded + those that we do not want. This list is updated every 100\n",
    "# iterations of the loop and stored as \"gdelt_downloaded_files.txt\". It\n",
    "# also contains the number of the last counter to avoid the files to overwrite.\n",
    "\n",
    "try: # if the list was previously saved we load it.\n",
    "    dfiles = np.genfromtxt(dfolder + 'gdelt_downloaded_files.txt', delimiter = '\\t', dtype=\"str\").tolist()\n",
    "    # the number of the counter where the previous iterations stopped; set this\n",
    "    # only if you area downloading the whole database\n",
    "    #ii = int(dfiles[-1])+1\n",
    "    # otherwise (for monthly updates), set it to zero:\n",
    "    ii = 0\n",
    "    dfiles = dfiles[:-1]\n",
    "except: # if the files does not exist (start from scratch)\n",
    "    dfiles = ['md5sums', 'filesizes', 'GDELT.MASTERREDUCEDV2.1979-2013.zip']\n",
    "    ii = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************\n",
      "\n",
      "Retrieving 20230323.export.CSV.zip (1/3805)...\n",
      "\n",
      "****************\n",
      "\n",
      "Retrieving 20221110.export.CSV.zip (2/3805)...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: looping over list of links obtained above:\n",
    "df_gdelt = pd.DataFrame()\n",
    "\n",
    "for l in links:\n",
    "    if l['href'] not in dfiles:\n",
    "\n",
    "        print('****************\\n\\nRetrieving ' + l['href'] + \" (\" + str(ii + 1) + \"/\" + str(len(links) - 3) + ')...\\n')\n",
    "        durl = 'http://data.gdeltproject.org/events/' + l['href']\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                path = download(durl, dfolder, kind=\"zip\", replace=True)\n",
    "            except (RequestException, HTTPError, RuntimeError) as e:\n",
    "                if isinstance(e, HTTPError) and e.code == 404:\n",
    "                    print(\"Failed to download \" + l['href'] + \" due to 404 error. Skipping...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "            down = True\n",
    "            dfiles.append(l['href'])\n",
    "            fname = os.listdir(dfolder)\n",
    "            fname = [i for i in fname if i.lower().endswith('.csv')]\n",
    "            fname = fname[0]\n",
    "\n",
    "            if int(fname[0:4]) < 2013:\n",
    "                results = pd.read_csv(dfolder + fname, sep=\"\\t\", header=None, names=cnames_bef, low_memory=False)\n",
    "            elif int(fname[0:4]) == 2013 & int(fname[4:6]) <= 3:\n",
    "                results = pd.read_csv(dfolder + fname, sep=\"\\t\", header=None, names=cnames_bef, low_memory=False)\n",
    "            else:\n",
    "                results = pd.read_csv(dfolder + fname, sep=\"\\t\", header=None, names=cnames_aft, low_memory=False)\n",
    "\n",
    "        except (RequestException, HTTPError, RuntimeError) as e:\n",
    "            down = False\n",
    "            if isinstance(e, HTTPError) and e.code == 404:\n",
    "                print(\"Failed to download \" + l['href'] + \" due to 404 error. Skipping...\")\n",
    "                continue\n",
    "            time.sleep(30)\n",
    "\n",
    "        # if the file was downloaded:\n",
    "        if down==True:\n",
    "            # loading the .csv file:\n",
    "            fname = os.listdir(dfolder) # getting the file name\n",
    "            fname = [i for i in fname if i.lower().endswith('.csv')] # remove system files from the list\n",
    "            fname = fname[0]\n",
    "            # importing as a pandas dataframe. Importantly, I need to check which header to use\n",
    "            # as it changes after march-2013:\n",
    "            if int(fname[0:4])<2013: # before 2013\n",
    "                results = pd.read_csv(dfolder + fname, sep = \"\\t\", header = None, names = cnames_bef,low_memory=False)\n",
    "            elif (int(fname[0:4])==2013 & int(fname[4:6])<=3): # jan to march 2013\n",
    "                results = pd.read_csv(dfolder + fname, sep = \"\\t\", header = None, names = cnames_bef,low_memory=False)\n",
    "            else: # after march 2013\n",
    "                results = pd.read_csv(dfolder + fname, sep = \"\\t\", header = None, names = cnames_aft,low_memory=False)\n",
    "            # counting all events found by country/event and ActionGeo_ADM1Code type:\n",
    "            df1 = results.groupby(['MonthYear','ActionGeo_ADM1Code', 'ActionGeo_CountryCode', 'EventRootCode']).size().reset_index(name = 'counts')\n",
    "            # sometimes the events have no rootcode so that I cannot make it an integer. I remove those:\n",
    "            df1['EventRootCode'] = pd.to_numeric(df1['EventRootCode'],errors='coerce') # forces event codes to numeric; those non numeric became NaN\n",
    "            df1 = df1.dropna(subset=['EventRootCode']) # removing these\n",
    "            df1['EventRootCode'] = df1['EventRootCode'].astype(int)\n",
    "            # reshaping it\n",
    "            df1 = df1.pivot_table(values = 'counts', index = ['ActionGeo_ADM1Code','ActionGeo_CountryCode', 'MonthYear'], columns = 'EventRootCode',aggfunc=np.sum).add_prefix('count_events_')\n",
    "            df1 = df1.reset_index()\n",
    "           \n",
    "\n",
    "            # the same but for the events in which actor1 or 2 is the government:\n",
    "            df2 = results.loc[(results['Actor1Type1Code']=='GOV') | (results['Actor2Type1Code']=='GOV') | (results['Actor1Type1Code']=='COP') | (results['Actor2Type1Code']=='COP') | (results['Actor1Type1Code']=='MIL') | (results['Actor2Type1Code']=='MIL')]\n",
    "            # df2 = results.loc[(results['Actor1Type1Code']=='GOV') | (results['Actor2Type1Code']=='GOV')]\n",
    "            df2 = df2.groupby(['MonthYear', 'ActionGeo_ADM1Code', 'EventRootCode']).size().reset_index(name = 'counts')\n",
    "            df2['EventRootCode'] = pd.to_numeric(df2['EventRootCode'],errors='coerce') # forces event codes to numeric; those non numeric became NaN\n",
    "            df2 = df2.dropna(subset=['EventRootCode']) # removing these\n",
    "            df2['EventRootCode'] = df2['EventRootCode'].astype(int)\n",
    "            df2 = df2.pivot_table(values = 'counts', index = ['ActionGeo_ADM1Code', 'ActionGeo_CountryCode', 'MonthYear'], columns = 'EventRootCode',aggfunc=np.sum).add_prefix('count_events_').add_suffix('_gov')\n",
    "            # df2 = df2.pivot(index='ActionGeo_CountryCode', columns = 'EventRootCode', values = 'counts').add_suffix('_gov')\n",
    "            df2 = df2.reset_index()\n",
    "\n",
    "            # the same but for the events in which actor1 is the opposition:\n",
    "            df3 = results.loc[(results['Actor1Type1Code']=='INS') | (results['Actor1Type1Code']=='OPP') | (results['Actor1Type1Code']=='REB') | (results['Actor2Type1Code']=='SEP')]\n",
    "            df3 = df3.groupby(['MonthYear', 'ActionGeo_ADM1Code', 'EventRootCode']).size().reset_index(name = 'counts')\n",
    "            df3['EventRootCode'] = pd.to_numeric(df3['EventRootCode'],errors='coerce') # forces event codes to numeric; those non numeric became NaN\n",
    "            df3 = df3.dropna(subset=['EventRootCode']) # removing these\n",
    "            df3['EventRootCode'] = df3['EventRootCode'].astype(int)\n",
    "            df3 = df3.pivot_table(values = 'counts', index = ['ActionGeo_ADM1Code', 'ActionGeo_CountryCode', 'MonthYear'], columns = 'EventRootCode',aggfunc=np.sum).add_prefix('count_events_').add_suffix('_opp')\n",
    "            df3 = df3.reset_index()\n",
    "\n",
    "           # Filter the dataset based on specific Actor1Type1Code and Actor2Type1Code values\n",
    "            df_filtered = results.loc[(results['Actor1Type1Code']=='INS') | (results['Actor1Type1Code']=='OPP') | (results['Actor1Type1Code']=='REB') | (results['Actor2Type1Code']=='SEP' )| (results['Actor1Type1Code']=='GOV') | (results['Actor2Type1Code']=='GOV') | (results['Actor1Type1Code']=='COP') | (results['Actor2Type1Code']=='COP') | (results['Actor1Type1Code']=='MIL') | (results['Actor2Type1Code']=='MIL')]\n",
    "\n",
    "            df4 = results.groupby(['ActionGeo_ADM1Code', 'ActionGeo_CountryCode', 'MonthYear']).agg(\n",
    "                Actor1Code_count=('Actor1Code', 'nunique'),\n",
    "                Actor1CountryCode_count=('Actor1CountryCode', 'nunique'),\n",
    "                Actor1KnownGroupCode_count=('Actor1KnownGroupCode', 'nunique'),\n",
    "                Actor1Type1Code_count=('Actor1Type1Code', 'nunique'),\n",
    "                Actor2Code_count=('Actor2Code', 'nunique'),\n",
    "                Actor2CountryCode_count=('Actor2CountryCode', 'nunique'),\n",
    "                Actor2KnownGroupCode_count=('Actor2KnownGroupCode', 'nunique'),\n",
    "                Actor2Type1Code_count=('Actor2Type1Code', 'nunique'),\n",
    "                AvgGoldsteinScale=('GoldsteinScale', 'mean')\n",
    "            ).reset_index()\n",
    "\n",
    "\n",
    "                  # merging them:\n",
    "            df = pd.merge(df1,df2,how='outer')\n",
    "            df = pd.merge(df,df3,how='outer')\n",
    "            df = pd.merge(df, df4, how='outer')\n",
    "            # adding year and month on Masterfile's format:\n",
    "            df['year'] = [int(str(i)[0:4]) for i in df['MonthYear'].tolist()]\n",
    "            df['month'] = [int(str(i)[4:6]) for i in df['MonthYear'].tolist()]\n",
    "            # removing monthyear var:\n",
    "            df = df.drop(columns=['MonthYear'])\n",
    "    \n",
    "            # make sure the dataset has all variable names (assign zero misses some):\n",
    "            for cname in var_list:\n",
    "                if cname not in df.columns:\n",
    "                    df[cname]=0\n",
    "\n",
    "            if ii in np.arange(0,100001,100): # the initial or every hundredth iteration\n",
    "                df_gdelt = df\n",
    "            else: # appending it:\n",
    "                df_gdelt = pd.concat([df_gdelt, df], ignore_index=True)\n",
    "\n",
    "                # here I aggregate (collapse) again the data by month-year-country\n",
    "                # to make sure that events dated in time periods different than the\n",
    "                # file are aggregated in their corrected date group. Importantly, events\n",
    "                # do not repeat across different bulk files.\n",
    "                df_gdelt = df_gdelt.groupby(['ActionGeo_ADM1Code', 'ActionGeo_CountryCode', 'year', 'month']).agg(\n",
    "                    {**{f'count_events_{i}': 'sum' for i in range(1, 21)},\n",
    "                    **{f'count_events_{i}_gov': 'sum' for i in range(1, 21)},\n",
    "                    **{f'count_events_{i}_opp': 'sum' for i in range(1, 21)},\n",
    "                    **{'Actor1Code_count': 'sum',\n",
    "                        'Actor1CountryCode_count': 'sum',\n",
    "                        'Actor1KnownGroupCode_count': 'sum',\n",
    "                        'Actor1Type1Code_count': 'sum',\n",
    "                        'Actor2Code_count': 'sum',\n",
    "                        'Actor2CountryCode_count': 'sum',\n",
    "                        'Actor2KnownGroupCode_count': 'sum',\n",
    "                        'Actor2Type1Code_count': 'sum',\n",
    "                        'AvgGoldsteinScale': 'mean'}\n",
    "                }).reset_index()\n",
    "\n",
    "            del df, df1, df2, df3, df4, results # cleaning RAM\n",
    "            os.remove(dfolder + fname) # deleting temp .csv file\n",
    "            time.sleep(5)\n",
    "\n",
    "        if ii in np.arange(99,100000,100):\n",
    "            # exporting the temp 100th file:\n",
    "            df_gdelt.to_csv(dfolder + 'gdelt_reshaped_' + str(ii) + '.txt', index=False)\n",
    "            # exporting the list of files ever downloaded and the number of the last iteration\n",
    "            dfiles.append(str(ii))\n",
    "            np.savetxt(dfolder + 'gdelt_downloaded_files.txt', dfiles, delimiter=\"\\t\", fmt=\"%s\")\n",
    "            dfiles = dfiles[:-1]\n",
    "        ii+=1\n",
    "\n",
    "# saving the files for the last iteration:\n",
    "df_gdelt.to_csv(dfolder + 'gdelt_reshaped_' + str(ii) + '.txt', index=False)\n",
    "dfiles.append(str(ii))\n",
    "np.savetxt(dfolder + 'gdelt_downloaded_files.txt', dfiles, delimiter=\"\\t\", fmt=\"%s\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************\n",
      "\n",
      "Appending files to a unique dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/2425156106.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt.append(df,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: load all temp txt of the 100 iteration blocks and\n",
    "# append them together. As bulk files can contain events of other periods,\n",
    "# I collapse the data by country-year-month once again just to be sure.\n",
    "\n",
    "# list of files:\n",
    "files = os.listdir(dfolder)\n",
    "files = [i for i in files if i.lower().startswith('gdelt_reshaped_')]\n",
    "\n",
    "# looping over:\n",
    "print(\"\\n****************\\n\\nAppending files to a unique dataset...\\n\")\n",
    "cc = 0 # counter\n",
    "for f in files:\n",
    "    df = pd.read_csv(dfolder + f)\n",
    "    if cc==0:\n",
    "        df_gdelt = df\n",
    "    else:\n",
    "        df_gdelt = df_gdelt.append(df,ignore_index=True)\n",
    "    # final collapse:\n",
    "    df_gdelt = df_gdelt.groupby(['ActionGeo_ADM1Code', 'ActionGeo_CountryCode', 'year', 'month']).agg(\n",
    "    **{f'count_events_{i}': (f'count_events_{i}', 'sum') for i in range(1, 21)},\n",
    "    **{f'count_events_{i}_gov': (f'count_events_{i}_gov', 'sum') for i in range(1, 21)},\n",
    "    **{f'count_events_{i}_opp': (f'count_events_{i}_opp', 'sum') for i in range(1, 21)},\n",
    "    **{'Actor1Code_count': ('Actor1Code_count', 'sum'),\n",
    "       'Actor1CountryCode_count': ('Actor1CountryCode_count', 'sum'),\n",
    "       'Actor1KnownGroupCode_count': ('Actor1KnownGroupCode_count', 'sum'),\n",
    "       'Actor1Type1Code_count': ('Actor1Type1Code_count', 'sum'),\n",
    "       'Actor2Code_count': ('Actor2Code_count', 'sum'),\n",
    "       'Actor2CountryCode_count': ('Actor2CountryCode_count', 'sum'),\n",
    "       'Actor2KnownGroupCode_count': ('Actor2KnownGroupCode_count', 'sum'),\n",
    "       'Actor2Type1Code_count': ('Actor2Type1Code_count', 'sum'),\n",
    "       'AvgGoldsteinScale': ('AvgGoldsteinScale', 'mean')}\n",
    ").reset_index()\n",
    "    cc+=1\n",
    "    del df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>isocode</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>count_events_1</th>\n",
       "      <th>count_events_2</th>\n",
       "      <th>count_events_3</th>\n",
       "      <th>count_events_4</th>\n",
       "      <th>count_events_5</th>\n",
       "      <th>count_events_6</th>\n",
       "      <th>...</th>\n",
       "      <th>count_events_20_opp</th>\n",
       "      <th>Actor1Code_count</th>\n",
       "      <th>Actor1CountryCode_count</th>\n",
       "      <th>Actor1KnownGroupCode_count</th>\n",
       "      <th>Actor1Type1Code_count</th>\n",
       "      <th>Actor2Code_count</th>\n",
       "      <th>Actor2CountryCode_count</th>\n",
       "      <th>Actor2KnownGroupCode_count</th>\n",
       "      <th>Actor2Type1Code_count</th>\n",
       "      <th>AvgGoldsteinScale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1920</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1981</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1981</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1983</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265814</th>\n",
       "      <td>ZI10</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265815</th>\n",
       "      <td>ZI10</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265816</th>\n",
       "      <td>ZI10</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265817</th>\n",
       "      <td>ZI10</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>174.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.983073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265818</th>\n",
       "      <td>ZI10</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1265819 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ActionGeo_ADM1Code isocode  year  month  count_events_1  \\\n",
       "0                       AA     ABW  1920      1             2.0   \n",
       "1                       AA     ABW  1981     10             2.0   \n",
       "2                       AA     ABW  1981     12             0.0   \n",
       "3                       AA     ABW  1983      1             0.0   \n",
       "4                       AA     ABW  1983      2             6.0   \n",
       "...                    ...     ...   ...    ...             ...   \n",
       "1265814               ZI10     ZWE  2023      1           102.0   \n",
       "1265815               ZI10     ZWE  2023      2           150.0   \n",
       "1265816               ZI10     ZWE  2023      3            90.0   \n",
       "1265817               ZI10     ZWE  2023      4           174.0   \n",
       "1265818               ZI10     ZWE  2023      5            72.0   \n",
       "\n",
       "         count_events_2  count_events_3  count_events_4  count_events_5  \\\n",
       "0                   0.0             0.0             2.0             0.0   \n",
       "1                   0.0             2.0             0.0             0.0   \n",
       "2                   0.0             0.0            22.0             0.0   \n",
       "3                   0.0             0.0             0.0             0.0   \n",
       "4                   0.0             0.0             0.0             0.0   \n",
       "...                 ...             ...             ...             ...   \n",
       "1265814            54.0            54.0           126.0            46.0   \n",
       "1265815            46.0            36.0           172.0            44.0   \n",
       "1265816            38.0            18.0           126.0            68.0   \n",
       "1265817            74.0            24.0           200.0            78.0   \n",
       "1265818            40.0             8.0           190.0             8.0   \n",
       "\n",
       "         count_events_6  ...  count_events_20_opp  Actor1Code_count  \\\n",
       "0                   2.0  ...                  0.0               0.0   \n",
       "1                   0.0  ...                  0.0               0.0   \n",
       "2                   0.0  ...                  0.0               0.0   \n",
       "3                   0.0  ...                  0.0               0.0   \n",
       "4                   0.0  ...                  0.0               0.0   \n",
       "...                 ...  ...                  ...               ...   \n",
       "1265814            10.0  ...                  0.0               8.0   \n",
       "1265815            16.0  ...                  0.0               4.0   \n",
       "1265816            14.0  ...                  0.0               2.0   \n",
       "1265817             8.0  ...                  0.0              16.0   \n",
       "1265818             4.0  ...                  0.0              10.0   \n",
       "\n",
       "         Actor1CountryCode_count  Actor1KnownGroupCode_count  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "...                          ...                         ...   \n",
       "1265814                      0.0                         0.0   \n",
       "1265815                      0.0                         0.0   \n",
       "1265816                      0.0                         0.0   \n",
       "1265817                      2.0                         0.0   \n",
       "1265818                      0.0                         0.0   \n",
       "\n",
       "         Actor1Type1Code_count  Actor2Code_count  Actor2CountryCode_count  \\\n",
       "0                          0.0               0.0                      0.0   \n",
       "1                          0.0               0.0                      0.0   \n",
       "2                          0.0               0.0                      0.0   \n",
       "3                          0.0               0.0                      0.0   \n",
       "4                          0.0               0.0                      0.0   \n",
       "...                        ...               ...                      ...   \n",
       "1265814                    8.0              12.0                      4.0   \n",
       "1265815                    4.0               2.0                      0.0   \n",
       "1265816                    2.0               2.0                      2.0   \n",
       "1265817                   14.0               8.0                      8.0   \n",
       "1265818                    8.0               8.0                      4.0   \n",
       "\n",
       "         Actor2KnownGroupCode_count  Actor2Type1Code_count  AvgGoldsteinScale  \n",
       "0                               0.0                    0.0                NaN  \n",
       "1                               0.0                    0.0                NaN  \n",
       "2                               0.0                    0.0                NaN  \n",
       "3                               0.0                    0.0                NaN  \n",
       "4                               0.0                    0.0                NaN  \n",
       "...                             ...                    ...                ...  \n",
       "1265814                         0.0                    4.0          -2.875000  \n",
       "1265815                         0.0                    2.0          -2.000000  \n",
       "1265816                         0.0                    0.0         -10.000000  \n",
       "1265817                         2.0                    6.0          -1.983073  \n",
       "1265818                         0.0                    4.0          -5.875000  \n",
       "\n",
       "[1265819 rows x 73 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gdelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************\n",
      "\n",
      "Adding correct ISO codes...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: adding correct isocodes (GDELT uses the FIPS-2-digit isocode) to\n",
    "# match the masterfile:\n",
    "\n",
    "print(\"\\n****************\\n\\nAdding correct ISO codes...\\n\")\n",
    "ccodes = pd.read_csv('country_codes_fips_to_iso3c.txt', sep='\\t') # codes' list\n",
    "# merging them:\n",
    "df_gdelt = pd.merge(df_gdelt,ccodes,how='inner', left_on = 'ActionGeo_CountryCode', right_on = 'actiongeo_countrycode')\n",
    "# removing useless variables:\n",
    "#df_gdelt =df_gdelt.drop(columns=['actiongeo_countrycode', 'ActionGeo_CountryCode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: removing the temp files with 100 iterations each:\n",
    "#files = [os.remove(dfolder + fname) for fname in files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************\n",
      "\n",
      "Done! :) Exporting final dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/n94x31sj08bdmgwjs6ybxbf40000gn/T/ipykernel_76586/446373993.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gdelt = df_gdelt_2.append(df_gdelt,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# otherwise:\n",
    "print(\"\\n****************\\n\\nDone! :) Exporting final dataset...\\n\")\n",
    "if 'final_gdelt_bycountry.txt' in os.listdir(dfolder):\n",
    "    # loading and appending\n",
    "    df_gdelt_2 = pd.read_csv(dfolder + 'final_gdelt_bycountry.txt') # previously downloaded data\n",
    "    df_gdelt = df_gdelt_2.append(df_gdelt,ignore_index=True)\n",
    "    # final collapse:\n",
    "    df_gdelt = df_gdelt.groupby(['ActionGeo_ADM1Code', 'isocode', 'year', 'month']).agg(\n",
    "    **{f'count_events_{i}': (f'count_events_{i}', 'sum') for i in range(1, 21)},\n",
    "    **{f'count_events_{i}_gov': (f'count_events_{i}_gov', 'sum') for i in range(1, 21)},\n",
    "    **{f'count_events_{i}_opp': (f'count_events_{i}_opp', 'sum') for i in range(1, 21)},\n",
    "    **{'Actor1Code_count': ('Actor1Code_count', 'sum'),\n",
    "       'Actor1CountryCode_count': ('Actor1CountryCode_count', 'sum'),\n",
    "       'Actor1KnownGroupCode_count': ('Actor1KnownGroupCode_count', 'sum'),\n",
    "       'Actor1Type1Code_count': ('Actor1Type1Code_count', 'sum'),\n",
    "       'Actor2Code_count': ('Actor2Code_count', 'sum'),\n",
    "       'Actor2CountryCode_count': ('Actor2CountryCode_count', 'sum'),\n",
    "       'Actor2KnownGroupCode_count': ('Actor2KnownGroupCode_count', 'sum'),\n",
    "       'Actor2Type1Code_count': ('Actor2Type1Code_count', 'sum'),\n",
    "       'AvgGoldsteinScale': ('AvgGoldsteinScale', 'mean')}\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "    del df_gdelt_2\n",
    "    # saving it:\n",
    "    df_gdelt.to_csv(dfolder + 'final_gdelt_bycountry.txt', index=False) # .csv\n",
    "else:\n",
    "    df_gdelt.to_csv(dfolder + 'final_gdelt_bycountry.txt', index=False) # .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ActionGeo_ADM1Code', 'ActionGeo_CountryCode', 'year', 'month',\n",
       "       'count_events_1', 'count_events_2', 'count_events_3', 'count_events_4',\n",
       "       'count_events_5', 'count_events_6', 'count_events_7', 'count_events_8',\n",
       "       'count_events_9', 'count_events_10', 'count_events_11',\n",
       "       'count_events_12', 'count_events_13', 'count_events_14',\n",
       "       'count_events_15', 'count_events_16', 'count_events_17',\n",
       "       'count_events_18', 'count_events_19', 'count_events_20',\n",
       "       'count_events_1_gov', 'count_events_2_gov', 'count_events_3_gov',\n",
       "       'count_events_4_gov', 'count_events_5_gov', 'count_events_6_gov',\n",
       "       'count_events_7_gov', 'count_events_8_gov', 'count_events_9_gov',\n",
       "       'count_events_10_gov', 'count_events_11_gov', 'count_events_12_gov',\n",
       "       'count_events_13_gov', 'count_events_14_gov', 'count_events_15_gov',\n",
       "       'count_events_16_gov', 'count_events_17_gov', 'count_events_18_gov',\n",
       "       'count_events_19_gov', 'count_events_20_gov', 'count_events_1_opp',\n",
       "       'count_events_2_opp', 'count_events_3_opp', 'count_events_4_opp',\n",
       "       'count_events_5_opp', 'count_events_6_opp', 'count_events_7_opp',\n",
       "       'count_events_8_opp', 'count_events_9_opp', 'count_events_10_opp',\n",
       "       'count_events_11_opp', 'count_events_12_opp', 'count_events_13_opp',\n",
       "       'count_events_14_opp', 'count_events_15_opp', 'count_events_16_opp',\n",
       "       'count_events_17_opp', 'count_events_18_opp', 'count_events_19_opp',\n",
       "       'count_events_20_opp', 'Actor1Code_count', 'Actor1CountryCode_count',\n",
       "       'Actor1KnownGroupCode_count', 'Actor1Type1Code_count',\n",
       "       'Actor2Code_count', 'Actor2CountryCode_count',\n",
       "       'Actor2KnownGroupCode_count', 'Actor2Type1Code_count',\n",
       "       'AvgGoldsteinScale', 'actiongeo_countrycode', 'isocode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gdelt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/final_gdelt_bycountry.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum the count of events that have a length of 2 and divide by number of total event counts(count_events_1 - 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ActionGeo_ADM1Code', 'isocode', 'year', 'month', 'count_events_1',\n",
       "       'count_events_2', 'count_events_3', 'count_events_4', 'count_events_5',\n",
       "       'count_events_6', 'count_events_7', 'count_events_8', 'count_events_9',\n",
       "       'count_events_10', 'count_events_11', 'count_events_12',\n",
       "       'count_events_13', 'count_events_14', 'count_events_15',\n",
       "       'count_events_16', 'count_events_17', 'count_events_18',\n",
       "       'count_events_19', 'count_events_20', 'count_events_1_gov',\n",
       "       'count_events_2_gov', 'count_events_3_gov', 'count_events_4_gov',\n",
       "       'count_events_5_gov', 'count_events_6_gov', 'count_events_7_gov',\n",
       "       'count_events_8_gov', 'count_events_9_gov', 'count_events_10_gov',\n",
       "       'count_events_11_gov', 'count_events_12_gov', 'count_events_13_gov',\n",
       "       'count_events_14_gov', 'count_events_15_gov', 'count_events_16_gov',\n",
       "       'count_events_17_gov', 'count_events_18_gov', 'count_events_19_gov',\n",
       "       'count_events_20_gov', 'count_events_1_opp', 'count_events_2_opp',\n",
       "       'count_events_3_opp', 'count_events_4_opp', 'count_events_5_opp',\n",
       "       'count_events_6_opp', 'count_events_7_opp', 'count_events_8_opp',\n",
       "       'count_events_9_opp', 'count_events_10_opp', 'count_events_11_opp',\n",
       "       'count_events_12_opp', 'count_events_13_opp', 'count_events_14_opp',\n",
       "       'count_events_15_opp', 'count_events_16_opp', 'count_events_17_opp',\n",
       "       'count_events_18_opp', 'count_events_19_opp', 'count_events_20_opp',\n",
       "       'Actor1Code_count', 'Actor1CountryCode_count',\n",
       "       'Actor1KnownGroupCode_count', 'Actor1Type1Code_count',\n",
       "       'Actor2Code_count', 'Actor2CountryCode_count',\n",
       "       'Actor2KnownGroupCode_count', 'Actor2Type1Code_count',\n",
       "       'AvgGoldsteinScale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows where 'ActionGeo_ADM1Code' has a length of 2\n",
    "filtered_df = df[df['ActionGeo_ADM1Code'].str.len() == 2]\n",
    "\n",
    "# calculate the numerator as the sum of event counts for the filtered rows\n",
    "numerator = filtered_df.loc[:, 'count_events_1':'count_events_20'].sum().sum()\n",
    "\n",
    "# calculate the denominator as the total count of all events\n",
    "denominator = df.loc[:, 'count_events_1':'count_events_20'].sum().sum()\n",
    "\n",
    "# calculate the ratio\n",
    "ratio = numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25021838836514265"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ActionGeo_ADM1Code', 'isocode', 'year', 'month', 'count_events_1',\n",
       "       'count_events_2', 'count_events_3', 'count_events_4', 'count_events_5',\n",
       "       'count_events_6', 'count_events_7', 'count_events_8', 'count_events_9',\n",
       "       'count_events_10', 'count_events_11', 'count_events_12',\n",
       "       'count_events_13', 'count_events_14', 'count_events_15',\n",
       "       'count_events_16', 'count_events_17', 'count_events_18',\n",
       "       'count_events_19', 'count_events_20', 'count_events_1_gov',\n",
       "       'count_events_2_gov', 'count_events_3_gov', 'count_events_4_gov',\n",
       "       'count_events_5_gov', 'count_events_6_gov', 'count_events_7_gov',\n",
       "       'count_events_8_gov', 'count_events_9_gov', 'count_events_10_gov',\n",
       "       'count_events_11_gov', 'count_events_12_gov', 'count_events_13_gov',\n",
       "       'count_events_14_gov', 'count_events_15_gov', 'count_events_16_gov',\n",
       "       'count_events_17_gov', 'count_events_18_gov', 'count_events_19_gov',\n",
       "       'count_events_20_gov', 'count_events_1_opp', 'count_events_2_opp',\n",
       "       'count_events_3_opp', 'count_events_4_opp', 'count_events_5_opp',\n",
       "       'count_events_6_opp', 'count_events_7_opp', 'count_events_8_opp',\n",
       "       'count_events_9_opp', 'count_events_10_opp', 'count_events_11_opp',\n",
       "       'count_events_12_opp', 'count_events_13_opp', 'count_events_14_opp',\n",
       "       'count_events_15_opp', 'count_events_16_opp', 'count_events_17_opp',\n",
       "       'count_events_18_opp', 'count_events_19_opp', 'count_events_20_opp',\n",
       "       'Actor1Code_count', 'Actor1CountryCode_count',\n",
       "       'Actor1KnownGroupCode_count', 'Actor1Type1Code_count',\n",
       "       'Actor2Code_count', 'Actor2CountryCode_count',\n",
       "       'Actor2KnownGroupCode_count', 'Actor2Type1Code_count',\n",
       "       'AvgGoldsteinScale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# create a boolean Series indicating whether each column sums to 0\n",
    "zero_sum_columns = (numeric_df.sum() == 0)\n",
    "\n",
    "# filter the Series to only include columns that sum to 0\n",
    "zero_sum_columns = zero_sum_columns[zero_sum_columns]\n",
    "\n",
    "# get the names of the columns that sum to 0\n",
    "zero_sum_column_names = zero_sum_columns.index\n",
    "\n",
    "print(zero_sum_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283886.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Actor1KnownGroupCode_count'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
